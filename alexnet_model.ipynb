{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4053a8",
   "metadata": {},
   "source": [
    "read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6268470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/asl_alphabet_train/asl_alphabet_train/'\n",
    "train_folders = os.listdir(train_dir)\n",
    "test_dir = '../input/asl_alphabet_test/asl_alphabet_test/'\n",
    "test_files = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfe716",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for folder in train_folders:\n",
    "    files = os.listdir(train_dir + folder)\n",
    "    print('Reading images from ' + train_dir + folder + '/ ...')\n",
    "    for file in files[:1000]:\n",
    "        img = cv2.imread(train_dir + folder + '/' + file)\n",
    "        img = cv2.resize(img, (227, 227))\n",
    "        x_train.append(img)\n",
    "        y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), x_train[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1203ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = [], []\n",
    "for file in test_files:\n",
    "    img = cv2.imread(test_dir + file)\n",
    "    img = cv2.resize(img, (227, 227))\n",
    "    x_test.append(img)\n",
    "    y_test.append(file.split('_')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185aaf0",
   "metadata": {},
   "source": [
    "pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding\n",
    "y_test_encoded = np.array(list(range(len(y_test))))\n",
    "y_train_encoded = np.array([y_test.index(i) if i != 'del' else 29 for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = np.eye(30)[y_test_encoded]\n",
    "y_train_encoded = np.eye(30)[y_train_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded.shape, y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9760dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5586969",
   "metadata": {},
   "source": [
    "Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a296f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "height = 227\n",
    "width = 227\n",
    "n_channels = 3\n",
    "n_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, height, width, n_channels])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bfeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # Convolutional Layer 1: 11x11 filters, 3 input channels, 96 output channels\n",
    "    'w1' : tf.Variable(tf.random_normal([11, 11, 3, 96])), \n",
    "    # Convolutional Layer 2: 5x5 filters, 96 input channels, 256 output channels\n",
    "    'w2' : tf.Variable(tf.random_normal([5, 5, 96, 256])),\n",
    "    # Convolutional Layer 3: 3x3 filters, 256 input channels, 384 output channels\n",
    "    'w3' : tf.Variable(tf.random_normal([3, 3, 256, 384])),\n",
    "    # Convolutional Layer 4: 3x3 filters, 384 input channels, 384 output channels\n",
    "    'w4' : tf.Variable(tf.random_normal([3, 3, 384, 384])),\n",
    "    # Convolutional Layer 5: 3x3 filters, 384 input channels, 256 output channels\n",
    "    'w5' : tf.Variable(tf.random_normal([3, 3, 384, 256])),\n",
    "    # Fully Connected Layer 1: 9216 input channels, 4096 output channels\n",
    "    'w6' : tf.Variable(tf.random_normal([9216, 4096])),\n",
    "    # Fully Connected Layer 2: 4096 input channels, 4096 output channels\n",
    "    'w7' : tf.Variable(tf.random_normal([4096, 4096])),\n",
    "    # Fully Connected Layer 3: 4096 input channels, 30(number of classes) output channels\n",
    "    'w8' : tf.Variable(tf.random_normal([4096, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f73ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([96])),\n",
    "    'b2' : tf.Variable(tf.random_normal([256])),\n",
    "    'b3' : tf.Variable(tf.random_normal([384])),\n",
    "    'b4' : tf.Variable(tf.random_normal([384])),\n",
    "    'b5' : tf.Variable(tf.random_normal([256])),\n",
    "    'b6' : tf.Variable(tf.random_normal([4096])),\n",
    "    'b7' : tf.Variable(tf.random_normal([4096])),\n",
    "    'b8' : tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function for creating a Convolutional Layer\n",
    "def conv2d(x, W, b, strides = 1, padding = 'SAME'):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = padding)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Wrapper function for creating a Pooling Layer\n",
    "def maxpool2d(x, k = 2, padding = 'VALID'):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(x, w, b):\n",
    "    x = tf.reshape(x, shape = [-1, 227, 227, 3])\n",
    "    \n",
    "    # Layer 1\n",
    "    conv1 = conv2d(x, w['w1'], b['b1'], strides = 4, padding = 'VALID') # Convolution\n",
    "    conv1 = maxpool2d(conv1) # Pooling\n",
    "    \n",
    "    # Layer 2\n",
    "    conv2 = conv2d(conv1, w['w2'], b['b2']) # Convolution\n",
    "    conv2 = maxpool2d(conv2) # Pooling\n",
    "    \n",
    "    # Layer 3\n",
    "    conv3 = conv2d(conv2, w['w3'], b['b3']) # Convolution\n",
    "    \n",
    "    # Layer 4\n",
    "    conv4 = conv2d(conv3, w['w4'], b['b4']) # Convolution\n",
    "    \n",
    "    # Layer 5\n",
    "    conv5 = conv2d(conv4, w['w5'], b['b5']) # Convolution\n",
    "    conv5 = maxpool2d(conv5) # Pooling\n",
    "    \n",
    "    # Layer 6\n",
    "    fc1 = tf.reshape(conv5, [-1, weights['w6'].get_shape().as_list()[0]]) # Channel Reshape\n",
    "    fc1 = tf.add(tf.matmul(fc1, w['w6']), b['b6']) # Linear Function\n",
    "    fc1 = tf.nn.relu(fc1) # Activation Function\n",
    "    \n",
    "    # Layer 7\n",
    "    fc2 = tf.add(tf.matmul(fc1, w['w7']), b['b7']) # Linear Function\n",
    "    fc2 = tf.nn.relu(fc2) # Activation Function\n",
    "    \n",
    "    # Layer 8\n",
    "    out = tf.add(tf.matmul(fc2, w['w8']), b['b8']) # Linear Function\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ab020",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = alexnet(X, weights, biases) # Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fffc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Function\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "# Training Operation\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1d80c",
   "metadata": {},
   "source": [
    "Training alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b081511",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Running Initializer\n",
    "    sess.run(init)\n",
    "    cost_hist, acc_hist = [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        _x, _y = next_batch(batch_size, x_train, y_train_encoded)\n",
    "        # Running Optimizer\n",
    "        sess.run(train_op, feed_dict = { X : _x, Y : _y })\n",
    "        if epoch % display_step == 0:\n",
    "            # Calculating Loss and Accuracy on the current Epoch\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict = { X : _x, Y : _y })\n",
    "            loss = loss\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n",
    "    W = sess.run(weights)\n",
    "    B = sess.run(biases)\n",
    "    print('-' * 70)\n",
    "    print('\\nOptimization Finished\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(cost_hist))), cost_hist)\n",
    "plt.title(\"Change in cost\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5aa1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(acc_hist))), acc_hist)\n",
    "plt.title(\"Change in accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb8fdd",
   "metadata": {},
   "source": [
    "check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = alexnet(X, weights, biases)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    acc = []\n",
    "    sess.run(init)\n",
    "    for i in range(100, 29001, 100):\n",
    "        acc.append(sess.run(accuracy, feed_dict = { X : x_train[i - 100 : i], Y : y_train_encoded[i - 100 : i] }))\n",
    "print('Accuracy on Training Data: ' + str(sum(acc) * 100 / len(acc)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11451e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_pred = sess.run(logits, feed_dict = { X : x_test })\n",
    "    acc = sess.run(accuracy, feed_dict = { X : x_test, Y : y_test_encoded }) * 100\n",
    "print('Accuracy on Test Data: ' + str(acc) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b5c69",
   "metadata": {},
   "source": [
    "vizualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b000e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [y_test[list(i).index(max(list(i)))] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(next_batch(12, x_test, y_pred), 'Predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
