{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac02de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3010 images belonging to 10 classes.\n",
      "Found 420 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_path = r'/Users/adithyaabhishek/Desktop/Capstone/code/gesture/train'\n",
    "test_path = r'/Users/adithyaabhishek/Desktop/Capstone/code/gesture/test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef64cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b61ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACGgAAADaCAYAAADw3eaaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUnklEQVR4nO3d0XKkOBIFUHvD///L3ocdb1czBRagRErlOU8T0+4uoJRIYMXNz+/v7w8AAAAAAAAAAOL8Z/QBAAAAAAAAAACszgYNAAAAAAAAAIBgNmgAAAAAAAAAAASzQQMAAAAAAAAAIJgNGgAAAAAAAAAAwWzQAAAAAAAAAAAI9nX0h5+fn99PHQis4Pv7+7Pl59QWnKO2IIbaghhqC2KoLYihtiCG2oIYagtitNSWuoJz9upKggYAAAAAAAAAQDAbNAAAAAAAAAAAgtmgAQAAAAAAAAAQzAYNAAAAAAAAAIBgNmgAAAAAAAAAAASzQQMAAAAAAAAAIJgNGgAAAAAAAAAAwWzQAAAAAAAAAAAIZoMGAAAAAAAAAEAwGzQAAAAAAAAAAILZoAEAAAAAAAAAEMwGDQAAAAAAAACAYDZoAAAAAAAAAAAEs0EDAAAAAAAAACCYDRoAAAAAAAAAAMFs0AAAAAAAAAAACGaDBgAAAAAAAABAMBs0AAAAAAAAAACC2aABAAAAAAAAABDMBg0AAAAAAAAAgGA2aAAAAAAAAAAABLNBAwAAAAAAAAAgmA0aAAAAAAAAAADBbNAAAAAAAAAAAAhmgwYAAAAAAAAAQDAbNAAAAAAAAAAAgtmgAQAAAAAAAAAQzAYNAAAAAAAAAIBgNmgAAAAAAAAAAASzQQMAAAAAAAAAINjX6AMAGOn7+/v///35+TnwSCDO6zjfMu4BAADief8AAAB8fEjQAAAAAAAAAAAIZ4MGAAAAAAAAAEAwLU6AcvbaPWz/v8hRAAAAoDftTgBYxVFr5R/mOoC/SdAAAAAAAAAAAAhmgwYAAAAAAAAAQDAtTgAmshcJJwaOKKJ1AaiqJYr34+P+/Gh9B+cc1aa6gT7UGTzDOxfoQ2tyYDUSNAAAAAAAAAAAgtmgAQAAAAAAAAAQzAYNAAAAAAAAAIBgX6MPAGBW+kTCnPb6JatTAH6zN4dAdZ59IIZ5B55lPoN1HM2hah3IToIGAAAAAAAAAEAwGzQAAAAAAAAAAIJpcTIZ0Uzw3qq1Ie4U2qgVADJpmbdWXd8CZPd0S8Xt5z31ObC6p2rr6DP3/szaj8zMJwD3SdAAAAAAAAAAAAhmgwYAAAAAAAAAQDAtTiYgEgrOEQkIAAAQY8TzlvciAAAAVCFBAwAAAAAAAAAgmA0aAAAAAAAAAADBtDiZ2MptHFY+NwDuE3MNQC/mFFiHdwkAAM/zTAXQlwQNAAAAAAAAAIBgNmgAAAAAAAAAAATT4oThRJSyZ9XotFXPC0YwbwAQzfMK8M7ec537BACZWOuSnTEMZCRBAwAAAAAAAAAgmA0aAAAAAAAAAADBbNAAAAAAAAAAAAj2NfoAAO54qsecXnZUYJwDANTxuvZr+RnrQ6rz/gFYRcsagHltvz9zBUA+EjQAAAAAAAAAAILZoAEAAAAAAAAAEEyLkySyxxuKTQMAAF7tPSNkfN4BavBug2yMWSpoHefWnr/TOiOn7L87emXeAqqQoAEAAAAAAAAAEMwGDQAAAAAAAACAYFqcAACHnoq4FGMIwMdHzWjliudMPr3HaYa1X4ZjZG6vdXJlPK0UWw+rylLb5rTcrrTyMW8AzEuCBgAAAAAAAABAMBs0AAAAAAAAAACCaXFCGLFp8Id6gPeu1IaIRgBmY60HUEtrhLz5AQC0XgHYkqABAAAAAAAAABDMBg0AAAAAAAAAgGBanCR0FI8oHorKtrWhHgAA8qsQh7vqeUGkqHuDlhRkZwwDP9wPAGBOEjQAAAAAAAAAAILZoAEAAAAAAAAAEMwGDQAAAAAAAACAYF+jDwBgz2sfYT0TYR3qGQAgv9c13euzW8vPA8Aszs5n27+zktbzJ4crYzujlc8NWJcEDQAAAAAAAACAYDZoAAAAAAAAAAAE0+JkMVViqyCDu3GHapiRVo3rBIA7PG/Bmjy7ccd2/LyOB61bgSe5zwBADhI0AAAAAAAAAACC2aABAAAAAAAAABBMixOaHMU1Us9eXJ5xAbzTI2LT/QXm1FLf6peetBgBAIA/tOkCqOnu+5HW+SPy3777OZlJ0AAAAAAAAAAACGaDBgAAAAAAAABAMC1OirobfbYXndMjxp68qrTCEa0NvzMfwHln66Z1DhodK2jeBKpx38tBJDzMQ9s8gGN3fwcz8/rUO0To+zvbrbs1v/dv976XzHyfiiBBAwAAAAAAAAAgmA0aAAAAAAAAAADBtDhZ2FEczF48zN14LHg1OpJo9OcDUMvTa6Kj1mJR7ezuqtIODeCHZ5I4rmdtkTHO2WLke6xBn64n7xJzqLh2zzJvqyGAuc16n+55XBXXCT1J0AAAAAAAAAAACGaDBgAAAAAAAABAMBs0AAAAAAAAAACCfY0+gBnc7bkzurdli9ZeQHv/f9Z+SYxxZcyO7uH4VG1l13I+eomxZ7V6gHdmHudPzHU9171w1+j15QitdV7lesxq73lpth69Pd9FZKnHmedx+plpPEb2+e7piWt25fhHf3/8babaevXEu3VYyeg16Yg69RxFtJnnn5mPrTIJGgAAAAAAAAAAwWzQAAAAAAAAAAAIpsXJx/0YtFnj3Y5kPGZqE1cYw7XkCuOmH/NxDsY88M5M9wZzSE57Y2il73N0nfT+/JW+myrurre9i7hHW5N1VZjDVuZ7ym37/VWfn3rO9XBG9drrrVotStAAAAAAAAAAAAhmgwYAAAAAAAAAQDAtTjrLGFUuko47rsR9ZqyTpzxxPUSMkoExB3OKjG+0PqinZ2x89vGzPX+R+uuo+F2udJ4Z7ydVeBcB8a60UVi5zkbPb3c/f7XvA4C5RM2Tq64tJGgAAAAAAAAAAASzQQMAAAAAAAAAIJgWJzS5EmkHLVaNJ7oq6npoa5JP63fme8rN9wfAOy3rAHNIPq3P1Z6R7vG+gllVbHnEWqqN4RnOcYZjYH0rrT29TyWa+3KcvXvR3vojex1L0AAAAAAAAAAACGaDBgAAAAAAAABAMC1ONnpGtWWPWjk6/73zEe9Tm1Y4a8l+D6ui5XvKUpszjbPtNZrp2HjGrHWS3VFtrRpZSJsrz2F7f6d3/WaI877y7EYOT90PM4zzrSzHSbwszzuzHldvVc6zupZ5Y8RztfmMivxOq5/q5w88R4IGAAAAAAAAAEAwGzQAAAAAAAAAAILZoAEAAAAAAAAAEOxr9AFUsVrvKr3xiGBc9XX3eq5wr8qmYg2MHmcVrzkA58w0V4yeN+nrbL/w7c8YD3Ddau/psvMd5NY6n6k7yGWm56C7ju45K50nrGJvzXC05si2tpCgAQAAAAAAAAAQzAYNAAAAAAAAAIBgWpwcOBs32ip77MpW1HUiP2MDniUuNI5rCzHORhaqP/a0xlxmX5NeOX41lMOVcRr13a5UM1eok/zutg8C4lmfPMO1hevcp4BIEjQAAAAAAAAAAILZoAEAAAAAAAAAEEyLk0aREZ+iFKmgekzuFVdi1FzbHHxPY7n+AGvbrpvc9/8Q05vDTM9OMx1LJPWwripjuCfvIrhj1pZdZ44HMmupwYr39rvnctRGE4i16nsMCRoAAAAAAAAAAMFs0AAAAAAAAAAACKbFCcOtFElDm9a4w72xsVK82l29r4V67Mc4bfNURFnP72PVWDX+Jg77eXu1dfRdqME1HX2vr2NAbVJB63z0xPqktTZ7fk5knZtD6vEu4ryoc1Z/NczWYmTVZzz1xJ4rY2Ol2oAIq84lWRw992Z7Zy9BAwAAAAAAAAAgmA0aAAAAAAAAAADBbNAAAAAAAAAAAAj2NfoAMpqtf95M9F/irCu9oCqOsyrnmZ3v6b0MPd/OWO18YEbZ+kYCPKH1XcSIe+jdZ7S94zw6/p6fQz3eRcDzWmoocg57om6vHLP7CaMZg3CNtSF3SNAAAAAAAAAAAAhmgwYAAAAAAAAAQDAtTjpoiS4TbwP3qKEYIn5ZlXsGPYkshHmox36Orp814jqOouJnqqErkfZX7gdaaDEL8xnVnW13sv07ezLWk/sBTzPO7rOmZGvmZ61VXVknzESCBgAAAAAAAABAMBs0AAAAAAAAAACCaXFCmGxxMsznbgzUqtGH0GKmqL3WOrt7nJH1PPoaMg/xs2OpRarX3V4NVL8uVZ2dk7KMk7vtTuCuqFoxTuG91vkswzx2N27dfQKe0fPdzkzvYIE8JGgAAAAAAAAAAASzQQMAAAAAAAAAIJgWJ8C0RIK9J16fs7KMk5mO0/0HgFmYk2ix6jNCa1T8lXNWW5xVfcy0nv9K9yC4a68eWuez6vcd+ql4b1Y/wMwkaAAAAAAAAAAABLNBAwAAAAAAAAAgmBYnQAmrxrgdRbWtes4QRfQhAJlY61HR67h/XbtdafGy92/B0+Nh+3nZ7+/qiTtWbdm11TKfbX/ulTqD90bUhnoErpCgAQAAAAAAAAAQzAYNAAAAAAAAAIBgNmgAAAAAAAAAAAT7Gn0AVUT2oWrpx3f0+Xf7+enbSgZXxmb2XpdV+nYCsDZrTV5VWd/snWdUDagtMtqrjSr3CXiaNRnEOKqtvTlNPXLWyusjNQDtVr4XZCNBAwAAAAAAAAAgmA0aAAAAAAAAAADBtDgBKEDUG7ynNsisYvsueJU9mtMcBP20tDvZ/hwAc6t4D9+eY0sLL+1OqOjuWK9wP4Ef5oY5SdAAAAAAAAAAAAhmgwYAAAAAAAAAQDAtTiZ2N2bpKLYmKsJJpBpPqD7Oqp8/69KugWxGR+4exd8e/RysqOeaKLJmZoritY5cV/X54Oh5STw8AJm0tPDam8+2Pwc/jt5lzLqOnO2dodoik9H1y3sSNAAAAAAAAAAAgtmgAQAAAAAAAAAQTIuTxcwaQQVRRNEyk72ISfbdrVvXnJmMHo9qAOY0WxwvVHIU9T563iafvXHiXQQ8o/p9+2y7E2jVMo+1znVaMgK0kaABAAAAAAAAABDMBg0AAAAAAAAAgGBanExmpRgyrSd42lF8LTxNxOTzXHNYk/mcjM6OW/MWvGcOIIPe7yIyPNd4/wLnqRNWNVNbk1nnTaCPleZSCRoAAAAAAAAAAMFs0AAAAAAAAAAACGaDBgAAAAAAAABAsK/RB8D9vlgr9dyBnl5r60qd6PsK8e7W6Z7tvzVrDZObcdWXOYyRRjyTjbiHqDOyeep5R23QU9QzzswqnjOc9USdqD8yyvAspbZgnFXrT4IGAAAAAAAAAEAwGzQAAAAAAAAAAIJpcTLAanHYq8bLsBZxmzC/yDpV9zAntclII57LVnsWhKedrSHzDD1daYNaofXqx4dag7Ou1LM6Yxaeo4BoFeY8CRoAAAAAAAAAAMFs0AAAAAAAAAAACKbFSUKt0S5in1jV3YhP7U542tE4c69+b3td1CrkpX6ZScV5Vw3yYzsWKtYDjFSl3Qk8QT1AXp5PWJG56Lzq9wIJGgAAAAAAAAAAwWzQAAAAAAAAAAAIpsUJUFprxOis0YnVY6BWMOvYmk3LtVEPRFGb56lHZjK6hkd/PgD99Wy9evRvA8Ao1Z9jzMe8U70u7lJXf0jQAAAAAAAAAAAIZoMGAAAAAAAAAEAwLU4WI16Hanq2h9j+fXFLPK11zLnXv9fasgiIoe6YxVPz5MxjfuZjA1jN9p7b+93EjMwzAEQbMR+a3/iNduXnqav3JGgAAAAAAAAAAASzQQMAAAAAAAAAIJgNGgAAAAAAAAAAwb5GH0BFFXtTwhOq1JaeXeyNgVnHbCT1AM9Sc9Cm4pwMwP+s2pvcOhCglp7vH80hsD51fo4EDQAAAAAAAACAYDZoAAAAAAAAAAAE0+IkodniEV+PR4QNxFBb8Id6gGepObLp3fZuz2zPZQDMZ9V2JzCTKnXmHTyzuPK81Tp+V65hWI256B4JGgAAAAAAAAAAwWzQAAAAAAAAAAAIpsUJsKwqEYfwozVWLGM9iEyDZ6k5yEXNAgCszXqPVWR8LwnvVPz9k7moHwkaAAAAAAAAAADBbNAAAAAAAAAAAAimxQkAFFMxfg3uWLlmRBMCADxj5TUlAHVln9+8F4F/UxfxJGgAAAAAAAAAAASzQQMAAAAAAAAAIJgWJ9wm6oYM9sZpxtg1uCvDuDe3MCvRncAs1DN3ZZ/TILOje3jPejRXABDNOhL+vebKUBfWiWNJ0AAAAAAAAAAACGaDBgAAAAAAAABAMBs0AAAAAAAAAACCfY0+AICRIvsu6+HFLDL0vIMZvNZKyz289T4/ogbNQQBUZQ4ku70x7LkO6jGnMaMV5iO1RbSWMeZ9YW0SNAAAAAAAAAAAgtmgAQAAAAAAAAAQTIsTgH9s451WiGuDTESsMZOz7U6ORLVCuXJcR5+hBmF+6hSgLnMAAMDzer4jfNXzfWGP49r7HGvQGBI0AAAAAAAAAACC2aABAAAAAAAAABBMi5MBVmibINKGCl7HuXgngFpG3N/PfuYKa0oA6MFzGQArMJ9BDLVFZr1bHDMHCRoAAAAAAAAAAMFs0AAAAAAAAAAACKbFyQDbOJoMUTMioKiupd0JjJZlbJpT4JwstQ2z2pt3stSWeRP+UA8ArMbcBkCrLO8x+J0EDQAAAAAAAACAYDZoAAAAAAAAAAAE0+IE4CTRg/C7K3XyGtGmzqhOZCHUZh6kMuMfgKtma1FsToNx1B8wMwkaAAAAAAAAAADBbNAAAAAAAAAAAAhmgwYAAAAAAAAAQLCv0QfAfi+sp/rk6cUFsIa79/Mr886Vz5yhDyzMSG3As57qUe55iwxGvJdoqY3Wz1dnAGxt54Ynnrd6vyMxvzGjo3EZVWdqAViNBA0AAAAAAAAAgGA2aAAAAAAAAAAABNPiZGKRsfFRMfiipgDyirqHa9tAFhXXMRXPGd5prYURz0Gvn6lmedqV2hjRdk+dAPCbEa21vA+hmit19sTabcRnsg7jhQgSNAAAAAAAAAAAgtmgAQAAAAAAAAAQ7FPMFgAAAAAAAABALAkaAAAAAAAAAADBbNAAAAAAAAAAAAhmgwYAAAAAAAAAQDAbNAAAAAAAAAAAgtmgAQAAAAAAAAAQzAYNAAAAAAAAAIBg/wVuQddsHpnpdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba915e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d53a1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 414,346\n",
      "Trainable params: 414,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e50a5b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 43s 143ms/step - loss: 0.5817 - accuracy: 0.8983 - val_loss: 0.0086 - val_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 38s 128ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 39s 129ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 40s 133ms/step - loss: 9.5547e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "loss of 0.0010199578246101737; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n",
    "imgs, labels = next(train_batches) # For getting next batch of imgs...\n",
    "\n",
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\n",
    "model.save('best_model_3.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b22fba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.008646437898278236, 0.0014067135052755475, 0.01157383807003498, 0.002773888409137726], 'val_accuracy': [0.9976190328598022, 1.0, 1.0, 1.0], 'loss': [0.5817267275276127, 0.0037575218146991764, 0.001387280053973501, 0.0009554708410368496], 'accuracy': [0.89833885, 0.99966776, 1.0, 1.0], 'lr': [0.001, 0.001, 0.001, 0.0005]}\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "loss of 0.0011117018293589354; accuracy of 100.0%\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 414,346\n",
      "Trainable params: 414,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "predictions on a small set of test data--\n",
      "\n",
      "Three   Two   Eight   Ten   Two   Two   One   Eight   Seven   Ten   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "Three   Two   Eight   Ten   Two   Two   One   Eight   Seven   Ten   (10, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.008646437898278236,\n",
       "  0.0014067135052755475,\n",
       "  0.01157383807003498,\n",
       "  0.002773888409137726],\n",
       " 'val_accuracy': [0.9976190328598022, 1.0, 1.0, 1.0],\n",
       " 'loss': [0.5817267275276127,\n",
       "  0.0037575218146991764,\n",
       "  0.001387280053973501,\n",
       "  0.0009554708410368496],\n",
       " 'accuracy': [0.89833885, 0.99966776, 1.0, 1.0],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.0005]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history2.history)\n",
    "\n",
    "imgs, labels = next(test_batches)\n",
    "\n",
    "model = keras.models.load_model(r\"best_model_3.h5\")\n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "scores #[loss, accuracy] on test data...\n",
    "model.metrics_names\n",
    "\n",
    "\n",
    "word_dict = {1:'Ten',0:'One',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "history2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd02dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
